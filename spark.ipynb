{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/tatiana/anaconda3/lib/python3.11/site-packages (3.4.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /Users/tatiana/anaconda3/lib/python3.11/site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf, col\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_colwidth', 400)\n",
    "\n",
    "from matplotlib import rcParams\n",
    "sns.set(context='notebook', style='whitegrid', rc={'figure.figsize': (18,4)})\n",
    "rcParams['figure.figsize'] = 18,4\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting random seed for notebook reproducability\n",
    "rnd_seed=23\n",
    "np.random.seed=rnd_seed\n",
    "np.random.set_state=rnd_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/15 13:44:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"mushrooms\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://desktop-ujqivrs:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>mushrooms</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x15a4a1450>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://desktop-ujqivrs:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>mushrooms</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=mushrooms>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tatiana/anaconda3/lib/python3.11/site-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x15a68eb10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext = SQLContext(spark.sparkContext)\n",
    "sqlContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUSHROOMS_DATA = 'mushrooms.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv(\"mushrooms.csv\",inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-----------+---------+-------+----+---------------+------------+---------+----------+-----------+----------+------------------------+------------------------+----------------------+----------------------+---------+----------+-----------+---------+-----------------+----------+-------+\n",
      "|class|cap-shape|cap-surface|cap-color|bruises|odor|gill-attachment|gill-spacing|gill-size|gill-color|stalk-shape|stalk-root|stalk-surface-above-ring|stalk-surface-below-ring|stalk-color-above-ring|stalk-color-below-ring|veil-type|veil-color|ring-number|ring-type|spore-print-color|population|habitat|\n",
      "+-----+---------+-----------+---------+-------+----+---------------+------------+---------+----------+-----------+----------+------------------------+------------------------+----------------------+----------------------+---------+----------+-----------+---------+-----------------+----------+-------+\n",
      "|    p|        x|          s|        n|      t|   p|              f|           c|        n|         k|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         s|      u|\n",
      "|    e|        x|          s|        y|      t|   a|              f|           c|        b|         k|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         n|      g|\n",
      "|    e|        b|          s|        w|      t|   l|              f|           c|        b|         n|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         n|      m|\n",
      "|    p|        x|          y|        w|      t|   p|              f|           c|        n|         n|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         s|      u|\n",
      "|    e|        x|          s|        g|      f|   n|              f|           w|        b|         k|          t|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        e|                n|         a|      g|\n",
      "+-----+---------+-----------+---------+-------+----+---------------+------------+---------+----------+-----------+----------+------------------------+------------------------+----------------------+----------------------+---------+----------+-----------+---------+-----------------+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- class: string (nullable = true)\n",
      " |-- cap-shape: string (nullable = true)\n",
      " |-- cap-surface: string (nullable = true)\n",
      " |-- cap-color: string (nullable = true)\n",
      " |-- bruises: string (nullable = true)\n",
      " |-- odor: string (nullable = true)\n",
      " |-- gill-attachment: string (nullable = true)\n",
      " |-- gill-spacing: string (nullable = true)\n",
      " |-- gill-size: string (nullable = true)\n",
      " |-- gill-color: string (nullable = true)\n",
      " |-- stalk-shape: string (nullable = true)\n",
      " |-- stalk-root: string (nullable = true)\n",
      " |-- stalk-surface-above-ring: string (nullable = true)\n",
      " |-- stalk-surface-below-ring: string (nullable = true)\n",
      " |-- stalk-color-above-ring: string (nullable = true)\n",
      " |-- stalk-color-below-ring: string (nullable = true)\n",
      " |-- veil-type: string (nullable = true)\n",
      " |-- veil-color: string (nullable = true)\n",
      " |-- ring-number: string (nullable = true)\n",
      " |-- ring-type: string (nullable = true)\n",
      " |-- spore-print-color: string (nullable = true)\n",
      " |-- population: string (nullable = true)\n",
      " |-- habitat: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for categoricalCol in columns:\n",
    "\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol+\"_encoded\").fit(df_pyspark)\n",
    "\n",
    "    df_pyspark = stringIndexer.transform(df_pyspark)\n",
    "\n",
    "    df_pyspark = df_pyspark.withColumn(categoricalCol+\"_encoded\", df_pyspark[categoricalCol+\"_encoded\"].cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_encoded = [col+'_encoded'for col in columns]\n",
    "\n",
    "encoded_df=df_pyspark.select(col_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+-------------------+-----------------+---------------+------------+-----------------------+--------------------+-----------------+------------------+-------------------+------------------+--------------------------------+--------------------------------+------------------------------+------------------------------+-----------------+------------------+-------------------+-----------------+-------------------------+------------------+---------------+\n",
      "|class_encoded|cap-shape_encoded|cap-surface_encoded|cap-color_encoded|bruises_encoded|odor_encoded|gill-attachment_encoded|gill-spacing_encoded|gill-size_encoded|gill-color_encoded|stalk-shape_encoded|stalk-root_encoded|stalk-surface-above-ring_encoded|stalk-surface-below-ring_encoded|stalk-color-above-ring_encoded|stalk-color-below-ring_encoded|veil-type_encoded|veil-color_encoded|ring-number_encoded|ring-type_encoded|spore-print-color_encoded|population_encoded|habitat_encoded|\n",
      "+-------------+-----------------+-------------------+-----------------+---------------+------------+-----------------------+--------------------+-----------------+------------------+-------------------+------------------+--------------------------------+--------------------------------+------------------------------+------------------------------+-----------------+------------------+-------------------+-----------------+-------------------------+------------------+---------------+\n",
      "|            1|                0|                  1|                0|              1|           6|                      0|                   0|                1|                 7|                  1|                 2|                               0|                               0|                             0|                             0|                0|                 0|                  0|                0|                        2|                 2|              4|\n",
      "|            0|                0|                  1|                3|              1|           4|                      0|                   0|                0|                 7|                  1|                 3|                               0|                               0|                             0|                             0|                0|                 0|                  0|                0|                        1|                 3|              1|\n",
      "|            0|                3|                  1|                4|              1|           5|                      0|                   0|                0|                 3|                  1|                 3|                               0|                               0|                             0|                             0|                0|                 0|                  0|                0|                        1|                 3|              5|\n",
      "|            1|                0|                  0|                4|              1|           6|                      0|                   0|                1|                 3|                  1|                 2|                               0|                               0|                             0|                             0|                0|                 0|                  0|                0|                        2|                 2|              4|\n",
      "|            0|                0|                  1|                1|              0|           0|                      0|                   1|                0|                 7|                  0|                 2|                               0|                               0|                             0|                             0|                0|                 0|                  0|                1|                        1|                 4|              1|\n",
      "+-------------+-----------------+-------------------+-----------------+---------------+------------+-----------------------+--------------------+-----------------+------------------+-------------------+------------------+--------------------------------+--------------------------------+------------------------------+------------------------------+-----------------+------------------+-------------------+-----------------+-------------------------+------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_encoded.remove('class_encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cap-shape_encoded',\n",
       " 'cap-surface_encoded',\n",
       " 'cap-color_encoded',\n",
       " 'bruises_encoded',\n",
       " 'odor_encoded',\n",
       " 'gill-attachment_encoded',\n",
       " 'gill-spacing_encoded',\n",
       " 'gill-size_encoded',\n",
       " 'gill-color_encoded',\n",
       " 'stalk-shape_encoded',\n",
       " 'stalk-root_encoded',\n",
       " 'stalk-surface-above-ring_encoded',\n",
       " 'stalk-surface-below-ring_encoded',\n",
       " 'stalk-color-above-ring_encoded',\n",
       " 'stalk-color-below-ring_encoded',\n",
       " 'veil-type_encoded',\n",
       " 'veil-color_encoded',\n",
       " 'ring-number_encoded',\n",
       " 'ring-type_encoded',\n",
       " 'spore-print-color_encoded',\n",
       " 'population_encoded',\n",
       " 'habitat_encoded']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureAssembler = VectorAssembler(inputCols=col_encoded,outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = featureAssembler.transform(encoded_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/15 14:19:32 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|            features|class_encoded|\n",
      "+--------------------+-------------+\n",
      "|(22,[1,3,4,7,8,9,...|            1|\n",
      "|(22,[1,2,3,4,8,9,...|            0|\n",
      "|(22,[0,1,2,3,4,8,...|            0|\n",
      "|(22,[2,3,4,7,8,9,...|            1|\n",
      "|(22,[1,2,6,8,10,1...|            0|\n",
      "+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.select(\"features\",\"class_encoded\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = output.randomSplit([0.8, 0.2], seed=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training data: 6471\n",
      "size of testing data: 1653\n"
     ]
    }
   ],
   "source": [
    "print(\"size of training data:\", train.count())\n",
    "print(\"size of testing data:\", test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'class_encoded', maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/15 14:56:57 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lrModel = lr.fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lrModel.transform(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+-------------------+-----------------+---------------+------------+-----------------------+--------------------+-----------------+------------------+-------------------+------------------+--------------------------------+--------------------------------+------------------------------+------------------------------+-----------------+------------------+-------------------+-----------------+-------------------------+------------------+---------------+--------------------+--------------------+--------------------+----------+\n",
      "|class_encoded|cap-shape_encoded|cap-surface_encoded|cap-color_encoded|bruises_encoded|odor_encoded|gill-attachment_encoded|gill-spacing_encoded|gill-size_encoded|gill-color_encoded|stalk-shape_encoded|stalk-root_encoded|stalk-surface-above-ring_encoded|stalk-surface-below-ring_encoded|stalk-color-above-ring_encoded|stalk-color-below-ring_encoded|veil-type_encoded|veil-color_encoded|ring-number_encoded|ring-type_encoded|spore-print-color_encoded|population_encoded|habitat_encoded|            features|       rawPrediction|         probability|prediction|\n",
      "+-------------+-----------------+-------------------+-----------------+---------------+------------+-----------------------+--------------------+-----------------+------------------+-------------------+------------------+--------------------------------+--------------------------------+------------------------------+------------------------------+-----------------+------------------+-------------------+-----------------+-------------------------+------------------+---------------+--------------------+--------------------+--------------------+----------+\n",
      "|            0|                0|                  0|                0|              0|           0|                      0|                   0|                0|                 2|                  1|                 0|                               3|                               3|                             3|                             3|                0|                 0|                  1|                0|                        0|                 1|              0|(22,[8,9,11,12,13...|[-13.001935995575...|[2.25595256313146...|       1.0|\n",
      "|            0|                0|                  0|                0|              1|           0|                      0|                   0|                0|                 1|                  0|                 0|                               0|                               0|                             0|                             0|                0|                 0|                  0|                0|                        1|                 0|              0|(22,[3,8,19],[1.0...|[4.34924746542390...|[0.98724818019234...|       0.0|\n",
      "|            0|                0|                  0|                0|              1|           0|                      0|                   0|                0|                 1|                  0|                 0|                               0|                               0|                             0|                             1|                0|                 0|                  0|                0|                        1|                 1|              0|(22,[3,8,14,19,20...|[4.71464232394643...|[0.99111655161229...|       0.0|\n",
      "|            0|                0|                  0|                0|              1|           0|                      0|                   0|                0|                 1|                  0|                 0|                               0|                               0|                             1|                             0|                0|                 0|                  0|                0|                        2|                 0|              0|(22,[3,8,13,19],[...|[4.39055792368841...|[0.98775791363336...|       0.0|\n",
      "|            0|                0|                  0|                0|              1|           0|                      0|                   0|                0|                 1|                  0|                 0|                               0|                               0|                             1|                             0|                0|                 0|                  0|                0|                        2|                 1|              0|(22,[3,8,13,19,20...|[4.63379505029886...|[0.99037571748552...|       0.0|\n",
      "+-------------+-----------------+-------------------+-----------------+---------------+------------+-----------------------+--------------------+-----------------+------------------+-------------------+------------------+--------------------------------+--------------------------------+------------------------------+------------------------------+-----------------+------------------+-------------------+-----------------+-------------------------+------------------+---------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassClassificationEvaluator_f53a3fe73754"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.setLabelCol(\"class_encoded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassClassificationEvaluator_f53a3fe73754"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.setPredictionCol(\"prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9915305505142167"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
